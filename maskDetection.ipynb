{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_images_and_labels(image_dir, label_dir, image_size=(128, 128)):\n",
    "    images = [] \n",
    "    labels = []\n",
    "\n",
    "    #go through the image files in the folder\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith('.jpeg'):\n",
    "            #make the path for the image and that images label\n",
    "            img_path = os.path.join(image_dir, filename)\n",
    "            label_path = os.path.join(label_dir, filename.replace('.jpeg', '.txt'))\n",
    "\n",
    "            # Load and resize image \n",
    "            img = imread(img_path) \n",
    "            #images might come in many sizes, making them consitent makes feature extraction easier \n",
    "            #also normalises to help in our model development\n",
    "            img_resized = resize(img, image_size, anti_aliasing=True) \n",
    "            images.append(img_resized)  # add to the list \n",
    "\n",
    "            # Read label\n",
    "            with open(label_path, 'r') as f:\n",
    "                label = int(f.read().strip()) #read the label and convert it to an interger\n",
    "            labels.append(label) # add to the list \n",
    "\n",
    "    #converts the two lists, image and label into numpy arrays \n",
    "    return np.array(images, dtype=np.float32), np.array(labels, dtype=np.int64)\n",
    "\n",
    "def prepare_datasets_skimage(\n",
    "    train_image_path, train_label_path,\n",
    "    test_image_path, test_labal_path,\n",
    "    image_size=(128, 128),\n",
    "    val_split=0.2,\n",
    "    seed=42\n",
    "):\n",
    "    # Load the whole training set both labels and images, they are resized and normalised \n",
    "    X_train_full, y_train_full = load_images_and_labels(train_image_path, train_label_path, image_size)\n",
    "    \n",
    "    #same with the test set \n",
    "    X_test, y_test = load_images_and_labels(test_image_path, test_labal_path, image_size)\n",
    "\n",
    "    # Split training data into train validation, standard split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_full, y_train_full, test_size=val_split, random_state=seed, stratify=y_train_full #ensure smae label distribution with stratify\n",
    "    )\n",
    "\n",
    "    #sanity check\n",
    "    print(f\"Train: {X_train.shape}, {y_train.shape}\")\n",
    "    print(f\"Validation: {X_val.shape}, {y_val.shape}\")\n",
    "    print(f\"Test: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load training and test data, resize, normalise, split the data into the sets, and returns as numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_path = '/Users/david/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents – David’s MacBook Pro/university/year 3/Computer vision/cw/CV2024_CW_Dataset/train/images'\n",
    "train_label_path = '/Users/david/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents – David’s MacBook Pro/university/year 3/Computer vision/cw/CV2024_CW_Dataset/train/labels'\n",
    "test_image_path = '/Users/david/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents – David’s MacBook Pro/university/year 3/Computer vision/cw/CV2024_CW_Dataset/test/images'\n",
    "test_label_path = '/Users/david/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents – David’s MacBook Pro/university/year 3/Computer vision/cw/CV2024_CW_Dataset/test/labels'\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = prepare_datasets_skimage(\n",
    "    train_image_path, train_label_path,\n",
    "    test_image_path, test_label_path,\n",
    "    img_size=(128, 128)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
